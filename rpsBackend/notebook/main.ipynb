{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-13T14:17:43.046939400Z",
     "start_time": "2025-01-13T14:17:29.892369100Z"
    }
   },
   "outputs": [],
   "source": [
    "import HandTrackingDynamic as htd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Backend CV utilizing Keras CNN\n",
    "This version is a backend version of Rock Paper Scissors. It uses a Keras CNN model to predict the hand gesture. The model was trained on a custom rock paper scissors dataset. Run this notebook to see a prediction of a hand gesture for rock paper scissors. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8c4bc63421efdff"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import math as math\n",
    "class HandTrackingDynamic:\n",
    "    def __init__(self, mode=False, maxHands=2, detectionCon=0.5, trackCon=0.5):\n",
    "        self.__mode__ = mode\n",
    "        self.__maxHands__ = maxHands\n",
    "        self.__detectionCon__ = detectionCon\n",
    "        self.__trackCon__ = trackCon\n",
    "        self.handsMp = mp.solutions.hands\n",
    "        self.hands = self.handsMp.Hands()\n",
    "        self.mpDraw = mp.solutions.drawing_utils\n",
    "        self.tipIds = [4, 8, 12, 16, 20]\n",
    "\n",
    "    def findFingers(self, frame, draw=True):\n",
    "        imgRGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        self.results = self.hands.process(imgRGB)\n",
    "        if self.results.multi_hand_landmarks:\n",
    "            for handLms in self.results.multi_hand_landmarks:\n",
    "                if draw:\n",
    "                    self.mpDraw.draw_landmarks(frame, handLms, self.handsMp.HAND_CONNECTIONS)\n",
    "\n",
    "        return frame\n",
    "\n",
    "    def findPosition(self, frame, handNo=0, handDraw=True, rectDraw=True):\n",
    "        xList = []\n",
    "        yList = []\n",
    "        bbox = []\n",
    "        self.lmsList = []\n",
    "        if self.results.multi_hand_landmarks:\n",
    "            myHand = self.results.multi_hand_landmarks[handNo]\n",
    "            for id, lm in enumerate(myHand.landmark):\n",
    "\n",
    "                h, w, c = frame.shape\n",
    "                cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "                xList.append(cx)\n",
    "                yList.append(cy)\n",
    "                self.lmsList.append([id, cx, cy])\n",
    "                if handDraw:\n",
    "                    cv2.circle(frame, (cx, cy), 5, (255, 0, 255), cv2.FILLED)\n",
    "\n",
    "            xmin, xmax = min(xList), max(xList)\n",
    "            ymin, ymax = min(yList), max(yList)\n",
    "            bbox = xmin, ymin, xmax, ymax\n",
    "            # print(\"Hands Keypoint\")\n",
    "            # print(bbox)\n",
    "            if rectDraw:\n",
    "                cv2.rectangle(frame, (xmin - 20, ymin - 20), (xmax + 20, ymax + 20),\n",
    "                              (0, 255, 0), 2)\n",
    "\n",
    "        return self.lmsList, bbox\n",
    "\n",
    "    def findFingerUp(self):\n",
    "        fingers = []\n",
    "\n",
    "        if self.lmsList[self.tipIds[0]][1] > self.lmsList[self.tipIds[0] - 1][1]:\n",
    "            fingers.append(1)\n",
    "        else:\n",
    "            fingers.append(0)\n",
    "\n",
    "        for id in range(1, 5):\n",
    "            if self.lmsList[self.tipIds[id]][2] < self.lmsList[self.tipIds[id] - 2][2]:\n",
    "                fingers.append(1)\n",
    "            else:\n",
    "                fingers.append(0)\n",
    "\n",
    "        return fingers\n",
    "\n",
    "    def findDistance(self, p1, p2, frame, draw=True, r=15, t=3):\n",
    "\n",
    "        x1, y1 = self.lmsList[p1][1:]\n",
    "        x2, y2 = self.lmsList[p2][1:]\n",
    "        cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "\n",
    "        if draw:\n",
    "            cv2.line(frame, (x1, y1), (x2, y2), (255, 0, 255), t)\n",
    "            cv2.circle(frame, (x1, y1), r, (255, 0, 255), cv2.FILLED)\n",
    "            cv2.circle(frame, (x2, y2), r, (255, 0, 0), cv2.FILLED)\n",
    "            cv2.circle(frame, (cx, cy), r, (0, 0.255), cv2.FILLED)\n",
    "        len = math.hypot(x2 - x1, y2 - y1)\n",
    "\n",
    "        return len, frame, [x1, y1, x2, y2, cx, cy]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-13T14:17:43.095768900Z",
     "start_time": "2025-01-13T14:17:43.063125400Z"
    }
   },
   "id": "83dd68a85a470ffd"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def verify_image_type(image):\n",
    "    print(\"Image shape:\", image.shape)\n",
    "    print(\"Image data type:\", image.dtype)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-13T14:17:43.096779Z",
     "start_time": "2025-01-13T14:17:43.076776600Z"
    }
   },
   "id": "3fb4ab42c1da0864"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\n",
    "def resize():\n",
    "    # Testing green background\n",
    "    # Open the image and ensure it has an alpha channel\n",
    "    image = Image.open('handFrame.png').convert(\"RGBA\")\n",
    "\n",
    "    # Create a green background\n",
    "    green_background = Image.new(\"RGBA\", image.size, (0, 255, 0, 255))\n",
    "\n",
    "    # Extract the alpha channel from the original image\n",
    "    alpha = image.getchannel(\"A\")\n",
    "\n",
    "    # Composite the green background and the image using the alpha channel as a mask\n",
    "    composite = Image.composite(image, green_background, alpha)\n",
    "\n",
    "    # Save the final image\n",
    "    composite.save(\"handBackgroundGreen.png\")\n",
    "    \n",
    "    image = Image.open('handBackgroundGreen.png')\n",
    "    img = image.convert(\"RGB\")\n",
    "    img = img.resize((128, 128), Image.LANCZOS) \n",
    "    print(\"finished resize and recoloration\")\n",
    "    return np.array(img) / 255.0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-13T14:17:43.110777400Z",
     "start_time": "2025-01-13T14:17:43.090305600Z"
    }
   },
   "id": "b63422459467d793"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "model = models.load_model('../rpsModel.keras') # load in trained model\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "detector = htd.HandTrackingDynamic()\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "\n",
    "picture = False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-13T14:17:45.223103Z",
     "start_time": "2025-01-13T14:17:43.102786Z"
    }
   },
   "id": "b9db54f857be3876"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished resize and recoloration\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 335ms/step\n",
      "[[0.9216428  0.04362069 0.03473658]]\n",
      "Paper\n",
      "finished resize and recoloration\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 63ms/step\n",
      "[[0.55047846 0.15157157 0.29795   ]]\n",
      "Paper\n",
      "finished resize and recoloration\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 78ms/step\n",
      "[[0.450083   0.44172445 0.10819257]]\n",
      "Paper\n",
      "finished resize and recoloration\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 83ms/step\n",
      "[[0.31905818 0.64428467 0.03665716]]\n",
      "Rock\n",
      "finished resize and recoloration\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 65ms/step\n",
      "[[0.27273887 0.628412   0.09884906]]\n",
      "Rock\n",
      "finished resize and recoloration\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 71ms/step\n",
      "[[0.07229963 0.9184136  0.00928675]]\n",
      "Rock\n",
      "finished resize and recoloration\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 81ms/step\n",
      "[[0.41041666 0.09062739 0.498956  ]]\n",
      "Scissors\n",
      "finished resize and recoloration\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 81ms/step\n",
      "[[0.00235718 0.20898345 0.7886594 ]]\n",
      "Scissors\n",
      "finished resize and recoloration\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 79ms/step\n",
      "[[0.01850061 0.03423949 0.9472599 ]]\n",
      "Scissors\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    orgFrame = frame.copy()\n",
    "    frame = detector.findFingers(frame, draw=False)\n",
    "    lmsList, bbox = detector.findPosition(frame, handDraw= False) #bbox should contain the bounding where the hand is\n",
    "    cv2.imshow('RPS Identification', frame)\n",
    "    if cv2.waitKey(1) == ord('p'):\n",
    "        picture = True\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "    if lmsList and picture:\n",
    "        xmin, ymin, xmax, ymax = bbox\n",
    "        handFrame = orgFrame[ymin - 25 :ymax + 25, xmin - 25:xmax + 25]\n",
    "        cv2.imwrite('handFrame.png', handFrame)\n",
    "        handArray = resize()\n",
    "        prediction = model.predict(np.expand_dims(handArray, axis=0))\n",
    "        print(prediction)\n",
    "        PAPER, ROCK, SCISSORS = prediction[0][0], prediction[0][1], prediction[0][2]\n",
    "\n",
    "        if ROCK > PAPER and ROCK > SCISSORS:\n",
    "            print(\"Rock\")\n",
    "        elif PAPER > ROCK and PAPER > SCISSORS:\n",
    "            print(\"Paper\");\n",
    "        else:\n",
    "            print(\"Scissors\")\n",
    "        picture = False\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-13T14:18:34.129996900Z",
     "start_time": "2025-01-13T14:17:45.206065Z"
    }
   },
   "id": "44fd3937499db3a6"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-13T14:18:34.130995600Z",
     "start_time": "2025-01-13T14:18:34.106030500Z"
    }
   },
   "id": "e8d75112837194c5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
